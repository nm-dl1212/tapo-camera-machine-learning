import streamlit as st
import requests
import time
import datetime

import os
import cv2
import numpy as np
from dotenv import load_dotenv

if os.path.exists(".env"):
    load_dotenv()

# ç’°å¢ƒå¤‰æ•°ã‚ˆã‚Šå–å¾—
BACKEND_URL = os.environ["BACKEND_URL"]  # FastAPI ã‚µãƒ¼ãƒãƒ¼URL
INTERVAL = 3  # ç§’
THRESHOLD = 50  # å‹•ä½“æ¤œçŸ¥ã®é–¾å€¤
MIN_AREA = 5000  # å‹•ä½“æ¤œçŸ¥ã®æœ€å°ã‚¨ãƒªã‚¢


st.set_page_config(page_title="Camera Control", layout="wide")

st.title("ğŸ¥ Camera Control Dashboard")

# ã‚¹ãƒ†ãƒ¼ãƒˆ
if "streaming" not in st.session_state:
    st.session_state.streaming = False

if "move_status" not in st.session_state:
    st.session_state.move_status = ""


if "prev_gray" not in st.session_state:
    st.session_state.prev_gray = None


if "is_detect" not in st.session_state:
    st.session_state.is_detect = False

# --- ã‚«ãƒ¡ãƒ©ç§»å‹• ---
def move_camera(direction: str):
    try:
        response = requests.post(f"{BACKEND_URL}/pan_tilt", json={"direction": direction, "duration": 0.5})
        if response.status_code == 200:
            st.session_state.move_status = response.json().get("message", "ç§»å‹•æˆåŠŸ")
        else:
            st.session_state.move_status = f"ç§»å‹•å¤±æ•—: {response.text}"
    except Exception as e:
        st.session_state.move_status = f"ã‚¨ãƒ©ãƒ¼: {str(e)}"




# --- ãƒ¢ãƒ¼ãƒ‰é¸æŠ ---
mode = st.radio(
    "ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„",
    ("é¡”ç‚¹ç¾¤è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰", "é™æ­¢ç”»ãƒ¢ãƒ¼ãƒ‰", "ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰", "å‹•ä½“æ¤œçŸ¥ãƒ¢ãƒ¼ãƒ‰"),
    horizontal=True,
)

# --- ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸå‡¦ç† ---
if mode == "é™æ­¢ç”»ãƒ¢ãƒ¼ãƒ‰":
    url = f"{BACKEND_URL}/snapshot"
    response = requests.get(url)
    if response.status_code == 200:
        st.image(response.content, caption="Snapshot", width="content")
    else:
        st.error("ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

elif mode == "é¡”ç‚¹ç¾¤è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰":
    url = f"{BACKEND_URL}/face"
    response = requests.get(url)
    if response.status_code == 200:
        st.image(response.content, caption="Face Mesh", width="content")
    else:
        st.error("é¡”ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

    # ç‰¹å¾´æ¤œå‡ºã‚’è¿½åŠ 
    feat_url = f"{BACKEND_URL}/features"
    feat_response = requests.get(feat_url)
    if feat_response.status_code == 200:
        st.subheader("ç‰¹å¾´æ¤œå‡ºçµæœ")
        st.json(feat_response.json())
    else:
        st.warning("ç‰¹å¾´ã‚’æ¤œçŸ¥ã§ãã¾ã›ã‚“ã§ã—ãŸ")

elif mode == "ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰":
    st.subheader("ğŸ“º ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ˜ åƒ")
    
    # TODO: ä¿®æ­£æ¤œè¨
    # ã“ã“ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ã«ãªã‚‹ã®ã§ã€ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®å…¬é–‹URLã«ã™ã‚‹å¿…è¦ã‚ã‚Šã€‚
    html_code = f"""
        <img src="{BACKEND_URL}/video" height="600" />
    """
    st.components.v1.html(html_code, height=600)


    # ã‚«ãƒ¡ãƒ©ç§»å‹•ãƒœã‚¿ãƒ³
    st.subheader("ã‚«ãƒ¡ãƒ©ç§»å‹•ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«")
    col1, col2, col3 = st.columns([1, 2, 1])
    with col1:
        if st.button("â¬†ï¸ ä¸Šã¸"):
            move_camera("up")
    with col2:
        left_col, right_col = st.columns([1, 1])
        with left_col:
            if st.button("â¬…ï¸ å·¦ã¸"):
                move_camera("left")
        with right_col:
            if st.button("â¡ï¸ å³ã¸"):
                move_camera("right")
    with col3:
        if st.button("â¬‡ï¸ ä¸‹ã¸"):
            move_camera("down")

    if st.session_state.move_status:
        st.info(st.session_state.move_status)


elif mode == "å‹•ä½“æ¤œçŸ¥ãƒ¢ãƒ¼ãƒ‰":
     # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ˜ åƒè¡¨ç¤ºï¼ˆå‹•ç”»ï¼‰
    html_code = f"""
        <img src="{BACKEND_URL}/video_motion" height="400" />
    """
    st.components.v1.html(html_code, height=400)

    
    img_placeholder = st.empty()  # ç”»åƒè¡¨ç¤ºç”¨ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€
    msg_placeholder = st.empty()  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºç”¨
    
    while True:
        try:
            # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå–å¾—
            resp = requests.get(f"{BACKEND_URL}/snapshot")
            img_array = np.frombuffer(resp.content, np.uint8)
            frame = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
            if frame is None:
                continue
                
            # ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‚’ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–ï¼†ã¼ã‹ã—
            curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            curr_gray = cv2.GaussianBlur(curr_gray, (21, 21), 0)
                
            is_detect = False
            if st.session_state.prev_gray is not None:
                # å·®åˆ†è¨ˆç®—
                frame_delta = cv2.absdiff(st.session_state.prev_gray, curr_gray)
                _, thresh_img = cv2.threshold(frame_delta, THRESHOLD, 255, cv2.THRESH_BINARY)
                contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                for cnt in contours:
                    if cv2.contourArea(cnt) > MIN_AREA: # é–¾å€¤ã‚’è¶…ãˆãŸã‚‰å‡¦ç†ã‚’ç¶šè¡Œ
                        # å‹•ãã®ã‚ã£ãŸç®‡æ‰€ã‚’çŸ©å½¢ã§å›²ã‚€
                        x, y, w, h = cv2.boundingRect(cnt)
                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)
            
                        # å‹•ãæ¤œçŸ¥ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
                        is_detect = True

            st.session_state.prev_gray = curr_gray  # æ›´æ–°
            st.session_state.detect = is_detect

            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
            if is_detect:
                dt_now = datetime.datetime.now() + datetime.timedelta(hours=9)
                img_placeholder.image(frame, channels="BGR")
                msg_placeholder.success(f"{dt_now}: å‹•ããŒæ¤œçŸ¥ã•ã‚Œã¾ã—ãŸï¼")

            time.sleep(INTERVAL)

        except Exception as e:
            msg_placeholder.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            time.sleep(INTERVAL)